{"cells":[{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"c955dabb425e4974a337ca7cc1b325ad","deepnote_cell_type":"text-cell-h1"},"source":"# Hyperparameter Tuning via Optuna","block_group":"e3b1c7a724374b57b4fbdee20425f187"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"b1511b4f67f0429384d252b3478319dc","deepnote_cell_type":"text-cell-h2"},"source":"## Simulated Annealing","block_group":"796711baafa1444bb884091b0425107e"},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"4264fa96084a48dbb113e1e15c004702","deepnote_cell_type":"text-cell-h3"},"source":"### Loading Libraries","block_group":"b3f8d8b7d3454986b251131ec39bb45b"},{"cell_type":"code","metadata":{"cell_id":"3f1700eb5852475bbbd6df5c2f1bce0d","deepnote_cell_type":"code"},"source":"# Numerical Computing\nimport numpy as np\n\n# Data Manipulation\nimport pandas as pd\n\n# Warnings\nimport warnings\n\n# Time\nimport time\n\n# Notebook Optimizer\nfrom tqdm.notebook import tqdm\n\n# Scikit-Learn\nfrom sklearn.metrics import f1_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\n# TensorFlow\nimport tensorflow as tf\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Sequential  \nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.layers import Dense, Dropout \n\n# Optuna\nimport optuna","block_group":"3f1700eb5852475bbbd6df5c2f1bce0d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"cecc1c87b9474ecb9c3e4b569054575d","deepnote_cell_type":"code"},"source":"warnings.filterwarnings(\"ignore\")","block_group":"483166a624df4388bfdfb29bd93e16df","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"3193abdcfc0548558cefb6b2c337a15c","deepnote_cell_type":"code"},"source":"from tqdm.notebook import tqdm\nimport time\n\nfor i in tqdm(range(10), desc=\"Loading\"):\n    time.sleep(0.1)","block_group":"8ba9916dc0ca419f9e326df3f909eebc","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"4187405a84a84fe69a1d2737700e5922","deepnote_cell_type":"code"},"source":"def create_model(trial, input_size): \n    model = Sequential()\n    model.add(Dense(input_size, input_shape=(input_size,), activation='relu')) \n\n    num_layers = trial.suggest_int('num_layers', 0, 3)\n    for layer_i in range(num_layers):\n        n_units = trial.suggest_int(f'n_units_layer_{layer_i}', 10, 50, step=5)\n        dropout_rate = trial.suggest_float(f'dropout_rate_layer_{layer_i}', 0.0, 0.5)\n        actv_func = trial.suggest_categorical(f'actv_func_layer_{layer_i}', ['relu', 'tanh', 'elu'])\n\n        model.add(Dropout(dropout_rate))\n        model.add(Dense(n_units, activation=actv_func))\n\n    model.add(Dense(1, activation='sigmoid'))\n    return model","block_group":"91e89db82ef54de4a99ce2d48e372e8c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"d8662d4bdef745b08cc1d8ad9b34d692","deepnote_cell_type":"code"},"source":"def create_optimizer(trial):\n    opt_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n    if opt_name == 'SGD':\n        return SGD(\n            learning_rate=trial.suggest_float('sgd_lr', 1e-5, 1e-1, log=True),\n            momentum=trial.suggest_float('sgd_momentum', 1e-5, 1e-1, log=True)\n        )\n    else:\n        return Adam(learning_rate=trial.suggest_float('adam_lr', 1e-5, 1e-1, log=True))","block_group":"e9e43f3a1e674fbeb23f4c21b92f5caa","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"d5a8ad7dafcb44638238e400b65096fd","deepnote_cell_type":"code"},"source":"@tf.function\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n@tf.function\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n@tf.function\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))","block_group":"b25480fa93ce467581368200e5efbf81","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"4b7b1310e4fd4fe9a1c49280440e88e3","deepnote_cell_type":"code"},"source":"def preprocessing(X, numeric_preprocessor, categorical_preprocessor, is_train=True):\n    X = X.copy()\n    if is_train:\n        X[numerical_feats] = numeric_preprocessor.fit_transform(X[numerical_feats])\n        X_cat = categorical_preprocessor.fit_transform(X[categorical_feats]).toarray()\n    else:\n        X[numerical_feats] = numeric_preprocessor.transform(X[numerical_feats])\n        X_cat = categorical_preprocessor.transform(X[categorical_feats]).toarray()\n\n    X_cat = pd.DataFrame(X_cat, columns=categorical_preprocessor.get_feature_names_out())\n    X = X.drop(columns=categorical_feats).reset_index(drop=True)\n    X = pd.concat([X, X_cat], axis=1)\n    return X, numeric_preprocessor, categorical_preprocessor","block_group":"11a0b42108ee466090dfc93cca86f8de","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"5f3d69f5157244c6b69d8da3f472e37e","deepnote_cell_type":"code"},"source":"def train(trial, df_train, df_val=None, use_pruner=False):\n    X_train, y_train = df_train.drop(columns=['y']), df_train['y']\n    X_val, y_val = None, None\n\n    if df_val is not None:\n        X_val, y_val = df_val.drop(columns=['y']), df_val['y']\n\n    # Preprocessing\n    numeric_preprocessor = StandardScaler()\n    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n    X_train, numeric_preprocessor, categorical_preprocessor = preprocessing(X_train, numeric_preprocessor, categorical_preprocessor, is_train=True)\n    \n    if df_val is not None:\n        X_val, _, _ = preprocessing(X_val, numeric_preprocessor, categorical_preprocessor, is_train=False)\n\n    model = create_model(trial, X_train.shape[1])\n    optimizer = create_optimizer(trial)\n\n    callbacks = []\n    if use_pruner and df_val is not None:\n        callbacks.append(optuna.integration.TFKerasPruningCallback(trial, 'val_f1_m'))\n\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_m])\n    history = model.fit(\n        X_train, y_train,\n        epochs=trial.suggest_int('epoch', 15, 50),\n        batch_size=64,\n        validation_data=(X_val, y_val) if df_val is not None else None,\n        callbacks=callbacks,\n        verbose=0\n    )\n\n    if df_val is not None:\n        return np.mean(history.history['val_f1_m'])\n    return model","block_group":"e91c41a675ec47659f10084294cfbd77","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"94f3d1891b2242278cc78ac8b226d3ec","deepnote_cell_type":"code"},"source":"def objective(trial, df_train, use_pruner=False):\n    df_train_hp, df_val = train_test_split(df_train, test_size=0.1, random_state=0)\n    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n    return val_f1_score","block_group":"c92b253accee405695313294bc852505","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"335c80e16d924f51b19459e1be2e9e7f","deepnote_cell_type":"code"},"source":"def train_and_evaluate_final(df_train, df_test, **kwargs):\n    X_train, y_train = df_train.drop(columns=['y']), df_train['y']\n    X_test, y_test = df_test.drop(columns=['y']), df_test['y']\n\n    numeric_preprocessor = StandardScaler()\n    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n\n    X_train, numeric_preprocessor, categorical_preprocessor = preprocessing(X_train, numeric_preprocessor, categorical_preprocessor, is_train=True)\n    X_test, _, _ = preprocessing(X_test, numeric_preprocessor, categorical_preprocessor, is_train=False)\n\n    model = Sequential()\n    model.add(Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'))\n\n    for i in range(kwargs.get('num_layers', 0)):\n        model.add(Dropout(kwargs.get(f'dropout_rate_layer_{i}', 0)))\n        model.add(Dense(kwargs.get(f'n_units_layer_{i}', 10), activation=kwargs.get(f'actv_func_layer_{i}', 'relu')))\n\n    model.add(Dense(1, activation='sigmoid'))\n\n    opt_name = kwargs.get('optimizer', 'Adam')\n    if opt_name == 'SGD':\n        optimizer = SGD(\n            learning_rate=kwargs.get('sgd_lr', 1e-5),\n            momentum=kwargs.get('sgd_momentum', 1e-5)\n        )\n    else:\n        optimizer = Adam(learning_rate=kwargs.get('adam_lr', 1e-5))\n\n    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_m])\n    model.fit(X_train, y_train, epochs=kwargs.get('epoch', 15), batch_size=64, verbose=1)\n\n    y_test_pred_proba = model.predict(X_test)\n    y_test_pred = [1 if x > 0.5 else 0 for x in y_test_pred_proba]\n\n    print(\"=\" * 100)\n    print(\"F1-Score on Test Data:\", f1_score(y_test, y_test_pred))","block_group":"940d73d9200e46179cf45360938ddc9c","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"2443bb51bfd84a1899e11ef914e553ca","deepnote_cell_type":"text-cell-h2"},"source":"## Simulated Annealing","block_group":"6d77396511da40cbb73cc92f1a20ab03"},{"cell_type":"code","metadata":{"cell_id":"6da92d94b7c84476906693809dfebc74","deepnote_cell_type":"code"},"source":"df = pd.read_csv(\"/work/train.csv\", sep=\";\")","block_group":"37f2a6259f7f42458606630e4cd94c61","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"0664d30af0df4304a13f50ab8332ae6f","deepnote_cell_type":"code"},"source":"df['y'] = df['y'].map({'yes':1,'no':0})","block_group":"57a501f611d146f288c53a25962dee47","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"da0074c42c8642e3b839756ea86b809b","deepnote_cell_type":"code"},"source":"df_train, df_test = train_test_split(df, test_size=0.1, random_state=0)","block_group":"601e5e58878d43ed9695327143b7fc35","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"c765599bfee1436f896eaaf405ecdcdf","deepnote_cell_type":"code"},"source":"numerical_feats = list(df_train.drop(columns='y').select_dtypes(include=np.number).columns)","block_group":"0baa0e5187fd49edb620c47007255d29","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"edd4e9f03f024068ab40e22a134ee87c","deepnote_cell_type":"code"},"source":"categorical_feats = list(df_train.drop(columns='y').select_dtypes(exclude=np.number).columns)","block_group":"a9ef7b8aef0644fc9ae7c624ee358171","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","metadata":{"formattedRanges":[],"cell_id":"894e7435fc0040598d34a643e2f9263b","deepnote_cell_type":"text-cell-h3"},"source":"### Performing Hyperparameter Tuning with Simulated Annealing","block_group":"e4b45b1ea70e4d1c9fbfddef68fb3dd9"},{"cell_type":"code","metadata":{"cell_id":"cb4e08ba942547df80ceced67b55e319","deepnote_cell_type":"code"},"source":"class SimulatedAnnealingSampler(optuna.samplers.BaseSampler):\n    '''Reference: https://github.com/optuna/optuna-examples/blob/main/samplers/simulated_annealing_sampler.py\n    '''\n    def __init__(self, temperature=100, cooldown_factor=0.9, neighbor_range_factor=0.1, seed=None):\n        self._rng = np.random.RandomState(seed)\n        self._independent_sampler = optuna.samplers.RandomSampler(seed=seed)\n        self._temperature = temperature\n        self.cooldown_factor = cooldown_factor\n        self.neighbor_range_factor = neighbor_range_factor\n        self._current_trial = None\n\n    def infer_relative_search_space(self, study, trial):\n        return optuna.samplers.intersection_search_space(study)\n\n    def sample_relative(self, study, trial, search_space):\n        if search_space == {}:\n            # The relative search space is empty (it means this is the first trial of a study).\n            return {}\n\n        # The rest of this method is an implementation of Simulated Annealing (SA) algorithm.\n        prev_trial = self._get_last_complete_trial(study)\n\n        # Update the current state of SA if the transition is accepted.\n        if self._rng.uniform(0, 1) <= self._transition_probability(study, prev_trial):\n            self._current_trial = prev_trial\n\n        # Pick a new neighbor (i.e., parameters).\n        params = self._sample_neighbor_params(search_space)\n\n        # Decrease the temperature via geometric cooling annealing schedule.\n        self._temperature *= self.cooldown_factor\n\n        return params\n\n    def _sample_neighbor_params(self, search_space):\n        # Generate a sufficiently near neighbor (i.e., parameters).\n        #\n        # In this example, we define a sufficiently near neighbor as\n        # `self.neighbor_range_factor * 100` percent region of the entire\n        # search space centered on the current point.\n\n        params = {}\n        for param_name, param_distribution in search_space.items():\n            if isinstance(param_distribution, optuna.distributions.CategoricalDistribution):\n                params[param_name] = self._rng.choice(param_distribution.choices)\n            else:\n                current_value = self._current_trial.params[param_name]\n                width = (\n                    param_distribution.high - param_distribution.low\n                ) * self.neighbor_range_factor\n                neighbor_low = max(current_value - width, param_distribution.low)\n                neighbor_high = min(current_value + width, param_distribution.high)\n                \n                if isinstance(param_distribution, optuna.distributions.UniformDistribution):\n                    params[param_name] = self._rng.uniform(neighbor_low, neighbor_high)\n                elif isinstance(param_distribution, optuna.distributions.LogUniformDistribution):\n                    params[param_name] = self._rng.uniform(np.log(max(1e-6,neighbor_low)), np.log(neighbor_high))\n                elif isinstance(param_distribution, optuna.distributions.DiscreteUniformDistribution):\n                    params[param_name] = self._rng.choice(np.linspace(neighbor_low, neighbor_high, param_distribution.q))\n                elif isinstance(param_distribution, optuna.distributions.IntUniformDistribution):\n                    params[param_name] = self._rng.choice(range(max(int(neighbor_low)-1,param_distribution.low), \n                                                                min(int(neighbor_high)+1,param_distribution.high), \n                                                                param_distribution.step))\n                elif isinstance(param_distribution, optuna.distributions.IntLogUniformDistribution):\n                    params[param_name] = self._rng.choice(range(max(int(np.log(max(1e-6,neighbor_low)))-1,param_distribution.low), \n                                                                min(int(np.log(neighbor_high))+1,param_distribution.high), \n                                                                param_distribution.step))\n                else:\n                    raise NotImplementedError(\n                        \"Unsupported distribution {}.\".format(param_distribution)\n                    )\n\n        return params\n\n    def _transition_probability(self, study, prev_trial):\n        if self._current_trial is None:\n            return 1.0\n\n        prev_value = prev_trial.value\n        current_value = self._current_trial.value\n\n        # `prev_trial` is always accepted if it has a better value than the current trial.\n        if study.direction == optuna.study.StudyDirection.MINIMIZE and prev_value <= current_value:\n            return 1.0\n        elif study.direction == optuna.study.StudyDirection.MAXIMIZE and prev_value >= current_value:\n            return 1.0\n\n        # Calculate the probability of accepting `prev_trial` that has a worse value than\n        # the current trial.\n        return np.exp(-abs(current_value - prev_value) / self._temperature)\n\n    @staticmethod\n    def _get_last_complete_trial(study):\n        complete_trials = study.get_trials(deepcopy=False, states=[optuna.trial.TrialState.COMPLETE])\n        return complete_trials[-1]\n\n    def sample_independent(self, study, trial, param_name, param_distribution):\n        # In this example, this method is invoked only in the first trial of a study.\n        # The parameters of the trial are sampled by using `RandomSampler` as follows.\n        return self._independent_sampler.sample_independent(\n            study, trial, param_name, param_distribution\n        )","block_group":"f5baab3dbdf34ae18c517599d37875a7","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"f68a4803d57e43a190eb4d745d2e9ee7","deepnote_cell_type":"code"},"source":"study = optuna.create_study(direction='maximize',\n                            sampler=SimulatedAnnealingSampler(seed=0),\n                           )\nstudy.optimize(lambda trial: objective(trial, df_train),\n               n_trials=50, n_jobs=-1\n              )","block_group":"5953808fc2a242e8aed65d8ee0b6641d","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"5569c35a59974837b502160d840042d6","deepnote_cell_type":"code"},"source":"print(\"Best Trial:\")\nbest_trial = study.best_trial\n\nprint(\"    Value: \", best_trial.value)\n\nprint(\"    Hyperparameters: \")\nfor key, value in best_trial.params.items():\n    print(f\"        {key}: {value}\")","block_group":"7012e9fc60ec4d5c857890977869a539","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"a5b1def7cd714771904bf7b650cda577","deepnote_cell_type":"code"},"source":"best_trial.params","block_group":"ea47563b3e934ffdacd2aa0777af61a0","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"code","metadata":{"cell_id":"c130ac47a1304118ac37f4242d64c4b3","deepnote_cell_type":"code"},"source":"train_and_evaluate_final(df_train, df_test, **best_trial.params)","block_group":"5a9bd0944e6d492a9b79e5f6b1076098","execution_count":null,"outputs":[],"outputs_reference":null,"content_dependencies":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=ecd9fc6f-49c4-4072-a24f-120524d21eaa' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iODBweCIgaGVpZ2h0PSI4MHB4IiB2aWV3Qm94PSIwIDAgODAgODAiIHZlcnNpb249IjEuMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayI+CiAgICA8IS0tIEdlbmVyYXRvcjogU2tldGNoIDU0LjEgKDc2NDkwKSAtIGh0dHBzOi8vc2tldGNoYXBwLmNvbSAtLT4KICAgIDx0aXRsZT5Hcm91cCAzPC90aXRsZT4KICAgIDxkZXNjPkNyZWF0ZWQgd2l0aCBTa2V0Y2guPC9kZXNjPgogICAgPGcgaWQ9IkxhbmRpbmciIHN0cm9rZT0ibm9uZSIgc3Ryb2tlLXdpZHRoPSIxIiBmaWxsPSJub25lIiBmaWxsLXJ1bGU9ImV2ZW5vZGQiPgogICAgICAgIDxnIGlkPSJBcnRib2FyZCIgdHJhbnNmb3JtPSJ0cmFuc2xhdGUoLTEyMzUuMDAwMDAwLCAtNzkuMDAwMDAwKSI+CiAgICAgICAgICAgIDxnIGlkPSJHcm91cC0zIiB0cmFuc2Zvcm09InRyYW5zbGF0ZSgxMjM1LjAwMDAwMCwgNzkuMDAwMDAwKSI+CiAgICAgICAgICAgICAgICA8cG9seWdvbiBpZD0iUGF0aC0yMCIgZmlsbD0iIzAyNjVCNCIgcG9pbnRzPSIyLjM3NjIzNzYyIDgwIDM4LjA0NzY2NjcgODAgNTcuODIxNzgyMiA3My44MDU3NTkyIDU3LjgyMTc4MjIgMzIuNzU5MjczOSAzOS4xNDAyMjc4IDMxLjY4MzE2ODMiPjwvcG9seWdvbj4KICAgICAgICAgICAgICAgIDxwYXRoIGQ9Ik0zNS4wMDc3MTgsODAgQzQyLjkwNjIwMDcsNzYuNDU0OTM1OCA0Ny41NjQ5MTY3LDcxLjU0MjI2NzEgNDguOTgzODY2LDY1LjI2MTk5MzkgQzUxLjExMjI4OTksNTUuODQxNTg0MiA0MS42NzcxNzk1LDQ5LjIxMjIyODQgMjUuNjIzOTg0Niw0OS4yMTIyMjg0IEMyNS40ODQ5Mjg5LDQ5LjEyNjg0NDggMjkuODI2MTI5Niw0My4yODM4MjQ4IDM4LjY0NzU4NjksMzEuNjgzMTY4MyBMNzIuODcxMjg3MSwzMi41NTQ0MjUgTDY1LjI4MDk3Myw2Ny42NzYzNDIxIEw1MS4xMTIyODk5LDc3LjM3NjE0NCBMMzUuMDA3NzE4LDgwIFoiIGlkPSJQYXRoLTIyIiBmaWxsPSIjMDAyODY4Ij48L3BhdGg+CiAgICAgICAgICAgICAgICA8cGF0aCBkPSJNMCwzNy43MzA0NDA1IEwyNy4xMTQ1MzcsMC4yNTcxMTE0MzYgQzYyLjM3MTUxMjMsLTEuOTkwNzE3MDEgODAsMTAuNTAwMzkyNyA4MCwzNy43MzA0NDA1IEM4MCw2NC45NjA0ODgyIDY0Ljc3NjUwMzgsNzkuMDUwMzQxNCAzNC4zMjk1MTEzLDgwIEM0Ny4wNTUzNDg5LDc3LjU2NzA4MDggNTMuNDE4MjY3Nyw3MC4zMTM2MTAzIDUzLjQxODI2NzcsNTguMjM5NTg4NSBDNTMuNDE4MjY3Nyw0MC4xMjg1NTU3IDM2LjMwMzk1NDQsMzcuNzMwNDQwNSAyNS4yMjc0MTcsMzcuNzMwNDQwNSBDMTcuODQzMDU4NiwzNy43MzA0NDA1IDkuNDMzOTE5NjYsMzcuNzMwNDQwNSAwLDM3LjczMDQ0MDUgWiIgaWQ9IlBhdGgtMTkiIGZpbGw9IiMzNzkzRUYiPjwvcGF0aD4KICAgICAgICAgICAgPC9nPgogICAgICAgIDwvZz4KICAgIDwvZz4KPC9zdmc+' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote_notebook_id":"d1d83065fba046d199a4a2292b185690"}}