{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61cf090-eaf7-4791-a7ab-3f30ccb7a80b",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning via Optuna\n",
    "\n",
    "## Global Optuna\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b52eb02-dc9f-4f3a-9238-f3c8c55622b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "468deeac-69a5-4024-b2ba-233cb8c1e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ddf61-8448-45f1-8640-ffb473d11dba",
   "metadata": {},
   "source": [
    "### Function Definition\n",
    "\n",
    "#### Placing Model Architecture Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0255f06f-b247-47fb-a9d3-b1d95e811330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial: optuna.trial.Trial, input_size: int): \n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_size,input_shape=(input_size,),activation='relu')) \n",
    "\n",
    "    num_layers = trial.suggest_int('num_layers',low=0,high=3)  \n",
    "    for layer_i in range(num_layers):  \n",
    "        n_units = trial.suggest_int(f'n_units_layer_{layer_i}',low=10,high=50,step=5)  \n",
    "        dropout_rate = trial.suggest_float(f'dropout_rate_layer_{layer_i}',low=0,high=0.5)  \n",
    "        actv_func = trial.suggest_categorical(f'actv_func_layer_{layer_i}',['relu','tanh','elu'])  \n",
    "\n",
    "        model.add(Dropout(dropout_rate))  \n",
    "        model.add(Dense(n_units,activation=actv_func)) \n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid')) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3967bf-95a7-49f3-82d9-0c22e52452f5",
   "metadata": {},
   "source": [
    "#### Optimizers Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76aebde1-3f60-425b-ae5d-28ce181459fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial: optuna.trial.Trial): \n",
    "\topt_kwargs = {} \n",
    "\topt_selected = trial.suggest_categorical('optimizer', ['Adam','SGD']) \n",
    "\tif opt_selected == 'SGD': \n",
    "\t\topt_kwargs['lr'] = trial.suggest_float('sgd_lr',1e-5,1e-1,log=True) \n",
    "\t\topt_kwargs['momentum'] = trial.suggest_float('sgd_momentum',1e-5,1e-1,log=True) \n",
    "\telse: #’Adam’ \n",
    "\t\topt_kwargs['lr'] = trial.suggest_float('adam_lr',1e-5,1e-1,log=True) \n",
    "\n",
    "\toptimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs) \n",
    "\treturn optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549afd0-9443-4b8b-97d4-00bfeb334716",
   "metadata": {},
   "source": [
    "#### Custom Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fae2ba8a-3cf6-4c19-ab52-38e6ece011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0404c88-b458-48ae-a589-2afbf81b553b",
   "metadata": {},
   "source": [
    "#### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a92cd480-63c7-49a0-b8d2-543a56bb0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X: pd.DataFrame, \n",
    "                  numeric_preprocessor, categorical_preprocessor,\n",
    "                  is_train = True\n",
    "                 ):\n",
    "    if is_train:\n",
    "        X[numerical_feats] = numeric_preprocessor.fit_transform(X[numerical_feats])\n",
    "        X_cat = categorical_preprocessor.fit_transform(X[categorical_feats]).toarray()\n",
    "        X_cat = pd.DataFrame(X_cat,columns=categorical_preprocessor.get_feature_names_out())\n",
    "        X = X.drop(columns=categorical_feats).reset_index(drop=True)\n",
    "        X = pd.concat([X,X_cat],axis=1)\n",
    "    else:\n",
    "        X[numerical_feats] = numeric_preprocessor.transform(X[numerical_feats])\n",
    "        X_cat = categorical_preprocessor.transform(X[categorical_feats]).toarray()\n",
    "        X_cat = pd.DataFrame(X_cat,columns=categorical_preprocessor.get_feature_names_out())\n",
    "        X = X.drop(columns=categorical_feats).reset_index(drop=True)\n",
    "        X = pd.concat([X,X_cat],axis=1)\n",
    "    \n",
    "    return X, numeric_preprocessor, categorical_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab11a88-3275-4c68-88f6-01fdc843dcfa",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be79fdc0-ec20-43c3-82ed-7b9e54a5815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trial, df_train: pd.DataFrame, df_val: pd.DataFrame = None, use_pruner: bool = False):\n",
    "    X_train,y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "    \n",
    "    if df_val is not None:\n",
    "        X_val,y_val = df_val.drop(columns=['y']), df_val['y'] \n",
    "\n",
    "    #Preprocessing\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    \n",
    "    X_train,numeric_preprocessor,categorical_preprocessor = preprocessing(X_train,\n",
    "                                                                          numeric_preprocessor,\n",
    "                                                                          categorical_preprocessor,\n",
    "                                                                          is_train=True)\n",
    "    if df_val is not None:\n",
    "        X_val,_,_ = preprocessing(X_val,\n",
    "                                  numeric_preprocessor,categorical_preprocessor,\n",
    "                                  is_train=False)\n",
    "\n",
    "    #Build model & optimizer\n",
    "    model = create_model(trial,X_train.shape[1])\n",
    "    optimizer = create_optimizer(trial)\n",
    "    \n",
    "    callbacks = []\n",
    "    if use_pruner:\n",
    "        callbacks.append(optuna.integration.TFKerasPruningCallback(trial,'val_f1_m'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,\n",
    "                  metrics=[f1_m],\n",
    "                 )\n",
    "    history = model.fit(X_train,y_train,\n",
    "                        epochs=trial.suggest_int('epoch',15,50),\n",
    "                        batch_size=64,\n",
    "                        validation_data=(X_val,y_val) if df_val is not None else None,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=False\n",
    "                       )\n",
    "    if df_val is not None:\n",
    "        return np.mean(history.history['val_f1_m'])\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c53415-d85e-44db-bb7e-e7e7dffe9fc7",
   "metadata": {},
   "source": [
    "#### The Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c0497e1-47e9-4e0c-b60e-a833c54bee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, df_train: pd.DataFrame, use_pruner: bool = False): \n",
    "    #Split into Train and Validation data\n",
    "    df_train_hp, df_val = train_test_split(df_train, test_size=0.1, random_state=0)\n",
    "    \n",
    "    # Train and Validate Model\n",
    "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
    "        \n",
    "    return val_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9812db-b4bc-4ff6-add6-f698b6068987",
   "metadata": {},
   "source": [
    "#### Final Training & Evaluation Function: `To Test The Best Set of Hyperparmeters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d662b5bb-b7bc-47b5-a112-1f1ac750b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_final(df_train: pd.DataFrame, df_test: pd.DataFrame, **kwargs):\n",
    "    X_train,y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "    X_test,y_test = df_test.drop(columns=['y']), df_test['y'] \n",
    "    \n",
    "    # Preprocessing\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    X_train,numeric_preprocessor,categorical_preprocessor = preprocessing(X_train,\n",
    "                                                                          numeric_preprocessor,\n",
    "                                                                          categorical_preprocessor,\n",
    "                                                                          is_train=True)\n",
    "    X_test,_,_ = preprocessing(X_test,numeric_preprocessor,categorical_preprocessor,\n",
    "                              is_train=False)\n",
    "\n",
    "    #Build model\n",
    "    input_size = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_size,input_shape=(input_size,),activation='relu')) \n",
    "\n",
    "    num_layers = kwargs.get('num_layers',0)  \n",
    "    for layer_i in range(num_layers):  \n",
    "        n_units = kwargs.get(f'n_units_layer_{layer_i}',0)  \n",
    "        dropout_rate = kwargs.get(f'dropout_rate_layer_{layer_i}',0)  \n",
    "        actv_func = kwargs.get(f'actv_func_layer_{layer_i}','relu')  \n",
    "\n",
    "        model.add(Dropout(dropout_rate))  \n",
    "        model.add(Dense(n_units,activation=actv_func)) \n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    #Build Optimizer\n",
    "    opt_kwargs = {} \n",
    "    opt_selected = kwargs.get('optimizer', 'Adam')\n",
    "    if opt_selected == 'SGD': \n",
    "        opt_kwargs['lr'] = kwargs.get('sgd_lr',1e-5) \n",
    "        opt_kwargs['momentum'] = kwargs.get('sgd_momentum',1e-5) \n",
    "    else: #’Adam’ \n",
    "        opt_kwargs['lr'] = kwargs.get('adam_lr',1e-5) \n",
    "\n",
    "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs) \n",
    "    \n",
    "    #Training process\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,\n",
    "                  metrics=[f1_m],\n",
    "                 )\n",
    "    print(model.summary())\n",
    "    history = model.fit(X_train,y_train,\n",
    "                        epochs=kwargs.get('epoch',15),\n",
    "                        batch_size=64,\n",
    "                        validation_data=None,\n",
    "                        verbose=True\n",
    "                       )\n",
    "    \n",
    "    # Evaluation Process\n",
    "    y_test_pred_probas = model.predict(X_test)\n",
    "    y_test_pred = [1 if x[0]>0.5 else 0 for x in y_test_pred_probas]\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    print(\"F1-Score on Test Data: \",f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fa91c-0669-4230-a514-8935149b3291",
   "metadata": {},
   "source": [
    "## TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ecf0b0a-c15c-4af2-bbb8-f1c79738341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/joaquinromero/Desktop/HPTP/data/train.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730766fc-afef-42ba-b1c7-9a234b2be920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a25603-d184-4752-86c0-aaee0e7c9eb2",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38361f39-a089-4f7e-ac20-46747f27dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b7e7d-d2e9-4a07-8392-16c0342dc0a1",
   "metadata": {},
   "source": [
    "#### Placing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47de4461-763d-47fa-b311-9303a3f15f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats = list(df_train.drop(columns='y').select_dtypes(include=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325add34-5fa4-4ba5-ac3b-bf17152e6fd7",
   "metadata": {},
   "source": [
    "#### Placing Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f88371bc-bfa9-4e1a-95ab-513e1f804555",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = list(df_train.drop(columns='y').select_dtypes(exclude=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62541d3c-7dde-4358-aa27-591b02e07ab2",
   "metadata": {},
   "source": [
    "### Performing Hyperparameter Tuning with TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "638e5652-01d1-4b66-9e8a-c98bea4fcf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-14 15:04:26,734] A new study created in memory with name: no-name-f0f92dbc-fbf0-48c1-8857-bde03bb4acc0\n",
      "Exception ignored in: <function tqdm.__del__ at 0x328ad0280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x328ad0280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/tqdm/std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/tqdm/notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "[W 2025-07-14 15:04:27,369] Trial 1 failed with parameters: {'num_layers': 0, 'optimizer': 'Adam', 'adam_lr': 0.00028822277572740075} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.00028822277572740075}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 62, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.00028822277572740075}\n",
      "[W 2025-07-14 15:04:27,373] Trial 8 failed with parameters: {'num_layers': 0, 'optimizer': 'Adam', 'adam_lr': 0.053286526049027366} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.053286526049027366}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 62, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.053286526049027366}\n",
      "[W 2025-07-14 15:04:27,378] Trial 12 failed with parameters: {'num_layers': 0, 'optimizer': 'SGD', 'sgd_lr': 0.009672926261040018, 'sgd_momentum': 0.015740504717097273} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.009672926261040018}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.009672926261040018}\n",
      "[W 2025-07-14 15:04:27,379] Trial 5 failed with parameters: {'num_layers': 0, 'optimizer': 'SGD', 'sgd_lr': 0.016029902303702936, 'sgd_momentum': 0.024646113584116124} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.016029902303702936}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.016029902303702936}\n",
      "[W 2025-07-14 15:04:27,382] Trial 0 failed with parameters: {'num_layers': 0, 'optimizer': 'SGD', 'sgd_lr': 0.00042252759417389185, 'sgd_momentum': 0.00014627074173394707} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.00042252759417389185}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.00042252759417389185}\n",
      "[W 2025-07-14 15:04:27,386] Trial 7 failed with parameters: {'num_layers': 2, 'n_units_layer_0': 45, 'dropout_rate_layer_0': 0.11075127281919683, 'actv_func_layer_0': 'elu', 'n_units_layer_1': 10, 'dropout_rate_layer_1': 0.19902634738469127, 'actv_func_layer_1': 'tanh', 'optimizer': 'SGD', 'sgd_lr': 0.0047716773643139525, 'sgd_momentum': 2.3922515760795792e-05} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.0047716773643139525}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.0047716773643139525}\n",
      "[W 2025-07-14 15:04:27,390] Trial 9 failed with parameters: {'num_layers': 2, 'n_units_layer_0': 20, 'dropout_rate_layer_0': 0.03708484289809888, 'actv_func_layer_0': 'tanh', 'n_units_layer_1': 25, 'dropout_rate_layer_1': 0.3031995739339508, 'actv_func_layer_1': 'tanh', 'optimizer': 'Adam', 'adam_lr': 0.0072438349843205185} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.0072438349843205185}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 62, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.0072438349843205185}\n",
      "[W 2025-07-14 15:04:27,392] Trial 4 failed with parameters: {'num_layers': 1, 'n_units_layer_0': 45, 'dropout_rate_layer_0': 0.14898888762867563, 'actv_func_layer_0': 'tanh', 'optimizer': 'Adam', 'adam_lr': 0.00019906806438059385} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.00019906806438059385}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 62, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.00019906806438059385}\n",
      "[W 2025-07-14 15:04:27,393] Trial 2 failed with parameters: {'num_layers': 1, 'n_units_layer_0': 30, 'dropout_rate_layer_0': 0.258167383911864, 'actv_func_layer_0': 'elu', 'optimizer': 'Adam', 'adam_lr': 7.003488132952191e-05} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 7.003488132952191e-05}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 62, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 7.003488132952191e-05}\n",
      "[W 2025-07-14 15:04:27,396] Trial 10 failed with parameters: {'num_layers': 2, 'n_units_layer_0': 20, 'dropout_rate_layer_0': 0.3699480785416567, 'actv_func_layer_0': 'tanh', 'n_units_layer_1': 10, 'dropout_rate_layer_1': 0.0006866816299661571, 'actv_func_layer_1': 'tanh', 'optimizer': 'Adam', 'adam_lr': 0.002254330813982463} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.002254330813982463}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/adam.py\", line 62, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.002254330813982463}\n",
      "[W 2025-07-14 15:04:27,407] Trial 1 failed with value None.\n",
      "[W 2025-07-14 15:04:27,410] Trial 13 failed with parameters: {'num_layers': 1, 'n_units_layer_0': 20, 'dropout_rate_layer_0': 0.06288022441242752, 'actv_func_layer_0': 'elu', 'optimizer': 'SGD', 'sgd_lr': 0.000343776905376768, 'sgd_momentum': 0.00258078043818156} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.000343776905376768}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.000343776905376768}\n",
      "[W 2025-07-14 15:04:27,410] Trial 8 failed with value None.\n",
      "[W 2025-07-14 15:04:27,417] Trial 12 failed with value None.\n",
      "[W 2025-07-14 15:04:27,420] Trial 5 failed with value None.\n",
      "[W 2025-07-14 15:04:27,423] Trial 6 failed with parameters: {'num_layers': 3, 'n_units_layer_0': 20, 'dropout_rate_layer_0': 0.3443759832147654, 'actv_func_layer_0': 'tanh', 'n_units_layer_1': 25, 'dropout_rate_layer_1': 0.029521364109328152, 'actv_func_layer_1': 'elu', 'n_units_layer_2': 30, 'dropout_rate_layer_2': 0.04905933281562358, 'actv_func_layer_2': 'relu', 'optimizer': 'SGD', 'sgd_lr': 0.0005907142635045575, 'sgd_momentum': 0.00273242082436942} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.0005907142635045575}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.0005907142635045575}\n",
      "[W 2025-07-14 15:04:27,426] Trial 0 failed with value None.\n",
      "[W 2025-07-14 15:04:27,429] Trial 11 failed with parameters: {'num_layers': 3, 'n_units_layer_0': 10, 'dropout_rate_layer_0': 0.4210436423198276, 'actv_func_layer_0': 'elu', 'n_units_layer_1': 10, 'dropout_rate_layer_1': 0.3024894389706958, 'actv_func_layer_1': 'tanh', 'n_units_layer_2': 45, 'dropout_rate_layer_2': 0.092229086873859, 'actv_func_layer_2': 'tanh', 'optimizer': 'SGD', 'sgd_lr': 0.00021784314789836254, 'sgd_momentum': 9.116493401445186e-05} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.00021784314789836254}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.00021784314789836254}\n",
      "[W 2025-07-14 15:04:27,429] Trial 7 failed with value None.\n",
      "[W 2025-07-14 15:04:27,430] Trial 3 failed with parameters: {'num_layers': 3, 'n_units_layer_0': 10, 'dropout_rate_layer_0': 0.3556401873762696, 'actv_func_layer_0': 'elu', 'n_units_layer_1': 40, 'dropout_rate_layer_1': 0.15638156097389244, 'actv_func_layer_1': 'relu', 'n_units_layer_2': 45, 'dropout_rate_layer_2': 0.04943288250205108, 'actv_func_layer_2': 'relu', 'optimizer': 'SGD', 'sgd_lr': 0.0006020451078898857, 'sgd_momentum': 0.08307655043403084} because of the following error: ValueError(\"Argument(s) not recognized: {'lr': 0.0006020451078898857}\").\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/2119055675.py\", line 4, in <lambda>\n",
      "    study.optimize(lambda trial: objective(trial, df_train),\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1556494251.py\", line 6, in objective\n",
      "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/1709104360.py\", line 22, in train\n",
      "    optimizer = create_optimizer(trial)\n",
      "  File \"/var/folders/m3/3_zd43kn4nn3q52cpx_b38g00000gn/T/ipykernel_26262/658140075.py\", line 10, in create_optimizer\n",
      "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/sgd.py\", line 60, in __init__\n",
      "    super().__init__(\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 21, in __init__\n",
      "    super().__init__(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py\", line 90, in __init__\n",
      "    raise ValueError(f\"Argument(s) not recognized: {kwargs}\")\n",
      "ValueError: Argument(s) not recognized: {'lr': 0.0006020451078898857}\n",
      "[W 2025-07-14 15:04:27,431] Trial 9 failed with value None.\n",
      "[W 2025-07-14 15:04:27,431] Trial 4 failed with value None.\n",
      "[W 2025-07-14 15:04:27,431] Trial 2 failed with value None.\n",
      "[W 2025-07-14 15:04:27,432] Trial 10 failed with value None.\n",
      "[W 2025-07-14 15:04:27,433] Trial 13 failed with value None.\n",
      "[W 2025-07-14 15:04:27,434] Trial 6 failed with value None.\n",
      "[W 2025-07-14 15:04:27,435] Trial 11 failed with value None.\n",
      "[W 2025-07-14 15:04:27,436] Trial 3 failed with value None.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 0.00028822277572740075}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                             sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m      3\u001b[0m                            )\n\u001b[0;32m----> 4\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m               \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/study.py:489\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    389\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    396\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    397\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py:101\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m completed:\n\u001b[0;32m--> 101\u001b[0m                         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m                 futures\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    104\u001b[0m                     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    105\u001b[0m                         _optimize_sequential,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     )\n\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py:161\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py:253\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    249\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    252\u001b[0m ):\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/optuna/study/_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      2\u001b[0m                             sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m      3\u001b[0m                            )\n\u001b[0;32m----> 4\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      5\u001b[0m                n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      6\u001b[0m               )\n",
      "Cell \u001b[0;32mIn[17], line 6\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, df_train, use_pruner)\u001b[0m\n\u001b[1;32m      3\u001b[0m df_train_hp, df_val \u001b[38;5;241m=\u001b[39m train_test_split(df_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Train and Validate Model\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m val_f1_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train_hp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pruner\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m val_f1_score\n",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trial, df_train, df_val, use_pruner)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#Build model & optimizer\u001b[39;00m\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(trial,X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pruner:\n",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mcreate_optimizer\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m#’Adam’ \u001b[39;00m\n\u001b[1;32m      8\u001b[0m \topt_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam_lr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m1e-5\u001b[39m,\u001b[38;5;241m1e-1\u001b[39m,log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m---> 10\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt_selected\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mopt_kwargs\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/adam.py:62\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     45\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     61\u001b[0m ):\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_scale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_scale_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_1 \u001b[38;5;241m=\u001b[39m beta_1\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_2 \u001b[38;5;241m=\u001b[39m beta_2\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/backend/tensorflow/optimizer.py:21\u001b[0m, in \u001b[0;36mTFOptimizer.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/HPTP/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:90\u001b[0m, in \u001b[0;36mBaseOptimizer.__init__\u001b[0;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `decay` is no longer supported and will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument(s) not recognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     name \u001b[38;5;241m=\u001b[39m auto_name(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Argument(s) not recognized: {'lr': 0.00028822277572740075}"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize',\n",
    "                            sampler=optuna.samplers.TPESampler(seed=0),\n",
    "                           )\n",
    "study.optimize(lambda trial: objective(trial, df_train),\n",
    "               n_trials=50, n_jobs=-1,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d900ea82-5c74-483b-83cb-e88bb20f7556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf37ffd-35c2-44a2-a912-4deb7554e61f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
