{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61cf090-eaf7-4791-a7ab-3f30ccb7a80b",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning via Optuna\n",
    "\n",
    "## Random Search\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b52eb02-dc9f-4f3a-9238-f3c8c55622b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "\n",
    "\n",
    "# Optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468deeac-69a5-4024-b2ba-233cb8c1e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "787c0710-e057-4a02-b4bc-22b20d384cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16f9aed45ae4c1f891f246d805ac0dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(10), desc=\"Loading\"):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ddf61-8448-45f1-8640-ffb473d11dba",
   "metadata": {},
   "source": [
    "### Function Definition\n",
    "\n",
    "#### Placing Model Architecture Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0255f06f-b247-47fb-a9d3-b1d95e811330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial: optuna.trial.Trial, input_size: int): \n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_size,input_shape=(input_size,),activation='relu')) \n",
    "\n",
    "    num_layers = trial.suggest_int('num_layers',low=0,high=3)  \n",
    "    for layer_i in range(num_layers):  \n",
    "        n_units = trial.suggest_int(f'n_units_layer_{layer_i}',low=10,high=50,step=5)  \n",
    "        dropout_rate = trial.suggest_float(f'dropout_rate_layer_{layer_i}',low=0,high=0.5)  \n",
    "        actv_func = trial.suggest_categorical(f'actv_func_layer_{layer_i}',['relu','tanh','elu'])  \n",
    "\n",
    "        model.add(Dropout(dropout_rate))  \n",
    "        model.add(Dense(n_units,activation=actv_func)) \n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid')) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3967bf-95a7-49f3-82d9-0c22e52452f5",
   "metadata": {},
   "source": [
    "#### Optimizers Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76aebde1-3f60-425b-ae5d-28ce181459fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(trial: optuna.trial.Trial): \n",
    "\topt_kwargs = {} \n",
    "\topt_selected = trial.suggest_categorical('optimizer', ['Adam','SGD']) \n",
    "\tif opt_selected == 'SGD': \n",
    "\t\topt_kwargs['lr'] = trial.suggest_float('sgd_lr',1e-5,1e-1,log=True) \n",
    "\t\topt_kwargs['momentum'] = trial.suggest_float('sgd_momentum',1e-5,1e-1,log=True) \n",
    "\telse: #’Adam’ \n",
    "\t\topt_kwargs['lr'] = trial.suggest_float('adam_lr',1e-5,1e-1,log=True) \n",
    "\n",
    "\toptimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs) \n",
    "\treturn optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549afd0-9443-4b8b-97d4-00bfeb334716",
   "metadata": {},
   "source": [
    "#### Custom Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae2ba8a-3cf6-4c19-ab52-38e6ece011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0404c88-b458-48ae-a589-2afbf81b553b",
   "metadata": {},
   "source": [
    "#### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92cd480-63c7-49a0-b8d2-543a56bb0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X: pd.DataFrame, \n",
    "                  numeric_preprocessor, categorical_preprocessor,\n",
    "                  is_train = True\n",
    "                 ):\n",
    "    if is_train:\n",
    "        X[numerical_feats] = numeric_preprocessor.fit_transform(X[numerical_feats])\n",
    "        X_cat = categorical_preprocessor.fit_transform(X[categorical_feats]).toarray()\n",
    "        X_cat = pd.DataFrame(X_cat,columns=categorical_preprocessor.get_feature_names_out())\n",
    "        X = X.drop(columns=categorical_feats).reset_index(drop=True)\n",
    "        X = pd.concat([X,X_cat],axis=1)\n",
    "    else:\n",
    "        X[numerical_feats] = numeric_preprocessor.transform(X[numerical_feats])\n",
    "        X_cat = categorical_preprocessor.transform(X[categorical_feats]).toarray()\n",
    "        X_cat = pd.DataFrame(X_cat,columns=categorical_preprocessor.get_feature_names_out())\n",
    "        X = X.drop(columns=categorical_feats).reset_index(drop=True)\n",
    "        X = pd.concat([X,X_cat],axis=1)\n",
    "    \n",
    "    return X, numeric_preprocessor, categorical_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab11a88-3275-4c68-88f6-01fdc843dcfa",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be79fdc0-ec20-43c3-82ed-7b9e54a5815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trial, df_train: pd.DataFrame, df_val: pd.DataFrame = None, use_pruner: bool = False):\n",
    "    X_train,y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "    \n",
    "    if df_val is not None:\n",
    "        X_val,y_val = df_val.drop(columns=['y']), df_val['y'] \n",
    "\n",
    "    #Preprocessing\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    \n",
    "    X_train,numeric_preprocessor,categorical_preprocessor = preprocessing(X_train,\n",
    "                                                                          numeric_preprocessor,\n",
    "                                                                          categorical_preprocessor,\n",
    "                                                                          is_train=True)\n",
    "    if df_val is not None:\n",
    "        X_val,_,_ = preprocessing(X_val,\n",
    "                                  numeric_preprocessor,categorical_preprocessor,\n",
    "                                  is_train=False)\n",
    "\n",
    "    #Build model & optimizer\n",
    "    model = create_model(trial,X_train.shape[1])\n",
    "    optimizer = create_optimizer(trial)\n",
    "    \n",
    "    callbacks = []\n",
    "    if use_pruner:\n",
    "        callbacks.append(optuna.integration.TFKerasPruningCallback(trial,'val_f1_m'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,\n",
    "                  metrics=[f1_m],\n",
    "                 )\n",
    "    history = model.fit(X_train,y_train,\n",
    "                        epochs=trial.suggest_int('epoch',15,50),\n",
    "                        batch_size=64,\n",
    "                        validation_data=(X_val,y_val) if df_val is not None else None,\n",
    "                        callbacks=callbacks,\n",
    "                        verbose=False\n",
    "                       )\n",
    "    if df_val is not None:\n",
    "        return np.mean(history.history['val_f1_m'])\n",
    "    else:\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c53415-d85e-44db-bb7e-e7e7dffe9fc7",
   "metadata": {},
   "source": [
    "#### The Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0497e1-47e9-4e0c-b60e-a833c54bee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial, df_train: pd.DataFrame, use_pruner: bool = False): \n",
    "    #Split into Train and Validation data\n",
    "    df_train_hp, df_val = train_test_split(df_train, test_size=0.1, random_state=0)\n",
    "    \n",
    "    # Train and Validate Model\n",
    "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
    "        \n",
    "    return val_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9812db-b4bc-4ff6-add6-f698b6068987",
   "metadata": {},
   "source": [
    "#### Final Training & Evaluation Function: `To Test The Best Set of Hyperparmeters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d662b5bb-b7bc-47b5-a112-1f1ac750b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_final(df_train: pd.DataFrame, df_test: pd.DataFrame, **kwargs):\n",
    "    X_train,y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "    X_test,y_test = df_test.drop(columns=['y']), df_test['y'] \n",
    "    \n",
    "    # Preprocessing\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    X_train,numeric_preprocessor,categorical_preprocessor = preprocessing(X_train,\n",
    "                                                                          numeric_preprocessor,\n",
    "                                                                          categorical_preprocessor,\n",
    "                                                                          is_train=True)\n",
    "    X_test,_,_ = preprocessing(X_test,numeric_preprocessor,categorical_preprocessor,\n",
    "                              is_train=False)\n",
    "\n",
    "    #Build model\n",
    "    input_size = X_train.shape[1]\n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_size,input_shape=(input_size,),activation='relu')) \n",
    "\n",
    "    num_layers = kwargs.get('num_layers',0)  \n",
    "    for layer_i in range(num_layers):  \n",
    "        n_units = kwargs.get(f'n_units_layer_{layer_i}',0)  \n",
    "        dropout_rate = kwargs.get(f'dropout_rate_layer_{layer_i}',0)  \n",
    "        actv_func = kwargs.get(f'actv_func_layer_{layer_i}','relu')  \n",
    "\n",
    "        model.add(Dropout(dropout_rate))  \n",
    "        model.add(Dense(n_units,activation=actv_func)) \n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    #Build Optimizer\n",
    "    opt_kwargs = {} \n",
    "    opt_selected = kwargs.get('optimizer', 'Adam')\n",
    "    if opt_selected == 'SGD': \n",
    "        opt_kwargs['lr'] = kwargs.get('sgd_lr',1e-5) \n",
    "        opt_kwargs['momentum'] = kwargs.get('sgd_momentum',1e-5) \n",
    "    else: #’Adam’ \n",
    "        opt_kwargs['lr'] = kwargs.get('adam_lr',1e-5) \n",
    "\n",
    "    optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs) \n",
    "    \n",
    "    #Training process\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optimizer,\n",
    "                  metrics=[f1_m],\n",
    "                 )\n",
    "    print(model.summary())\n",
    "    history = model.fit(X_train,y_train,\n",
    "                        epochs=kwargs.get('epoch',15),\n",
    "                        batch_size=64,\n",
    "                        validation_data=None,\n",
    "                        verbose=True\n",
    "                       )\n",
    "    \n",
    "    # Evaluation Process\n",
    "    y_test_pred_probas = model.predict(X_test)\n",
    "    y_test_pred = [1 if x[0]>0.5 else 0 for x in y_test_pred_probas]\n",
    "    \n",
    "    print(\"=\"*100)\n",
    "    print(\"F1-Score on Test Data: \",f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df194e4a-d2dd-4b0d-ae95-930e43cfc86e",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ecf0b0a-c15c-4af2-bbb8-f1c79738341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/joaquinromero/Desktop/HPTP/data/train.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730766fc-afef-42ba-b1c7-9a234b2be920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd45d394-53f3-4381-b0f5-be281b2da787",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38361f39-a089-4f7e-ac20-46747f27dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ab1f6-cf86-4c3a-9c79-2d2ab1001642",
   "metadata": {},
   "source": [
    "### Placing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47de4461-763d-47fa-b311-9303a3f15f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats = list(df_train.drop(columns='y').select_dtypes(include=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b8634a-38d0-46a6-9fe2-41daa7337cfb",
   "metadata": {},
   "source": [
    "### Placing Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236b1ae0-4acb-4ff7-9a07-93390b4f987e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = list(df_train.drop(columns='y').select_dtypes(exclude=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304a681-112c-4582-a163-4372b5875f5f",
   "metadata": {},
   "source": [
    "### Performing Hyperparameter Tuning with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd09a7-feb5-4dbb-aab5-1bd47b5a5d24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
