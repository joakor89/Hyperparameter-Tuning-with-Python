{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61cf090-eaf7-4791-a7ab-3f30ccb7a80b",
   "metadata": {},
   "source": [
    "# Hyperparamter Tuning via Optuna\n",
    "\n",
    "## Global Optuna\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b52eb02-dc9f-4f3a-9238-f3c8c55622b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "\n",
    "# Time\n",
    "import time\n",
    "\n",
    "# Notebook Optimizer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential  \n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout \n",
    "\n",
    "# Optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468deeac-69a5-4024-b2ba-233cb8c1e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c1a8bed-3297-414e-b401-7b438a8c599b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab790c3aee24cc3845fe3b6695c76c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(10), desc=\"Loading\"):\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f06e9390-5443-4f1e-a64d-7ebd2a892f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.73.1)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.10.0)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.5.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ddf61-8448-45f1-8640-ffb473d11dba",
   "metadata": {},
   "source": [
    "### Function Definition\n",
    "\n",
    "#### Placing Model Architecture Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0255f06f-b247-47fb-a9d3-b1d95e811330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(trial: optuna.trial.Trial, input_size: int): \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(input_size,input_shape=(input_size,),activation='relu')) \n",
    "\n",
    "#     num_layers = trial.suggest_int('num_layers',low=0,high=3)  \n",
    "#     for layer_i in range(num_layers):  \n",
    "#         n_units = trial.suggest_int(f'n_units_layer_{layer_i}',low=10,high=50,step=5)  \n",
    "#         dropout_rate = trial.suggest_float(f'dropout_rate_layer_{layer_i}',low=0,high=0.5)  \n",
    "#         actv_func = trial.suggest_categorical(f'actv_func_layer_{layer_i}',['relu','tanh','elu'])  \n",
    "\n",
    "#         model.add(Dropout(dropout_rate))  \n",
    "#         model.add(Dense(n_units,activation=actv_func)) \n",
    "\n",
    "#     model.add(Dense(1,activation='sigmoid')) \n",
    "#     return model \n",
    "\n",
    "# ---------------------------- OPTUNA: MODEL ----------------------------\n",
    "\n",
    "def create_model(trial, input_size): \n",
    "    model = Sequential()\n",
    "    model.add(Dense(input_size, input_shape=(input_size,), activation='relu')) \n",
    "\n",
    "    num_layers = trial.suggest_int('num_layers', 0, 3)\n",
    "    for layer_i in range(num_layers):\n",
    "        n_units = trial.suggest_int(f'n_units_layer_{layer_i}', 10, 50, step=5)\n",
    "        dropout_rate = trial.suggest_float(f'dropout_rate_layer_{layer_i}', 0.0, 0.5)\n",
    "        actv_func = trial.suggest_categorical(f'actv_func_layer_{layer_i}', ['relu', 'tanh', 'elu'])\n",
    "\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(n_units, activation=actv_func))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3967bf-95a7-49f3-82d9-0c22e52452f5",
   "metadata": {},
   "source": [
    "#### Optimizers Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76aebde1-3f60-425b-ae5d-28ce181459fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_optimizer(trial: optuna.trial.Trial): \n",
    "# \topt_kwargs = {} \n",
    "# \topt_selected = trial.suggest_categorical('optimizer', ['Adam','SGD']) \n",
    "# \tif opt_selected == 'SGD': \n",
    "# \t\topt_kwargs['lr'] = trial.suggest_float('sgd_lr',1e-5,1e-1,log=True) \n",
    "# \t\topt_kwargs['momentum'] = trial.suggest_float('sgd_momentum',1e-5,1e-1,log=True) \n",
    "# \telse: #’Adam’ \n",
    "# \t\topt_kwargs['lr'] = trial.suggest_float('adam_lr',1e-5,1e-1,log=True) \n",
    "\n",
    "# \toptimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs) \n",
    "# \treturn optimizer\n",
    "\n",
    "# ---------------------------- OPTUNA: OPTIMIZER ----------------------------\n",
    "\n",
    "def create_optimizer(trial):\n",
    "    opt_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
    "    if opt_name == 'SGD':\n",
    "        return SGD(\n",
    "            learning_rate=trial.suggest_float('sgd_lr', 1e-5, 1e-1, log=True),\n",
    "            momentum=trial.suggest_float('sgd_momentum', 1e-5, 1e-1, log=True)\n",
    "        )\n",
    "    else:\n",
    "        return Adam(learning_rate=trial.suggest_float('adam_lr', 1e-5, 1e-1, log=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549afd0-9443-4b8b-97d4-00bfeb334716",
   "metadata": {},
   "source": [
    "#### Custom Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fae2ba8a-3cf6-4c19-ab52-38e6ece011d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives + K.epsilon())\n",
    "#     return recall\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives + K.epsilon())\n",
    "#     return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# ---------------------------- PERSONALIZED METRICS ----------------------------\n",
    "\n",
    "@tf.function\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "@tf.function\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "@tf.function\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0404c88-b458-48ae-a589-2afbf81b553b",
   "metadata": {},
   "source": [
    "#### Preprocessing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a92cd480-63c7-49a0-b8d2-543a56bb0423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing(X: pd.DataFrame, \n",
    "#                   numeric_preprocessor, categorical_preprocessor,\n",
    "#                   is_train = True\n",
    "#                  ):\n",
    "#     if is_train:\n",
    "#         X[numerical_feats] = numeric_preprocessor.fit_transform(X[numerical_feats])\n",
    "#         X_cat = categorical_preprocessor.fit_transform(X[categorical_feats]).toarray()\n",
    "#         X_cat = pd.DataFrame(X_cat,columns=categorical_preprocessor.get_feature_names_out())\n",
    "#         X = X.drop(columns=categorical_feats).reset_index(drop=True)\n",
    "#         X = pd.concat([X,X_cat],axis=1)\n",
    "#     else:\n",
    "#         X[numerical_feats] = numeric_preprocessor.transform(X[numerical_feats])\n",
    "#         X_cat = categorical_preprocessor.transform(X[categorical_feats]).toarray()\n",
    "#         X_cat = pd.DataFrame(X_cat,columns=categorical_preprocessor.get_feature_names_out())\n",
    "#         X = X.drop(columns=categorical_feats).reset_index(drop=True)\n",
    "#         X = pd.concat([X,X_cat],axis=1)\n",
    "    \n",
    "#     return X, numeric_preprocessor, categorical_preprocessor\n",
    "\n",
    "# ---------------------------- PREPROCESSING ----------------------------\n",
    "\n",
    "def preprocessing(X, numeric_preprocessor, categorical_preprocessor, is_train=True):\n",
    "    X = X.copy()\n",
    "    if is_train:\n",
    "        X[numerical_feats] = numeric_preprocessor.fit_transform(X[numerical_feats])\n",
    "        X_cat = categorical_preprocessor.fit_transform(X[categorical_feats]).toarray()\n",
    "    else:\n",
    "        X[numerical_feats] = numeric_preprocessor.transform(X[numerical_feats])\n",
    "        X_cat = categorical_preprocessor.transform(X[categorical_feats]).toarray()\n",
    "\n",
    "    X_cat = pd.DataFrame(X_cat, columns=categorical_preprocessor.get_feature_names_out())\n",
    "    X = X.drop(columns=categorical_feats).reset_index(drop=True)\n",
    "    X = pd.concat([X, X_cat], axis=1)\n",
    "    return X, numeric_preprocessor, categorical_preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab11a88-3275-4c68-88f6-01fdc843dcfa",
   "metadata": {},
   "source": [
    "#### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be79fdc0-ec20-43c3-82ed-7b9e54a5815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(trial, df_train: pd.DataFrame, df_val: pd.DataFrame = None, use_pruner: bool = False):\n",
    "#     X_train,y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "    \n",
    "#     if df_val is not None:\n",
    "#         X_val,y_val = df_val.drop(columns=['y']), df_val['y'] \n",
    "\n",
    "#     #Preprocessing\n",
    "#     numeric_preprocessor = StandardScaler()\n",
    "#     categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    \n",
    "#     X_train,numeric_preprocessor,categorical_preprocessor = preprocessing(X_train,\n",
    "#                                                                           numeric_preprocessor,\n",
    "#                                                                           categorical_preprocessor,\n",
    "#                                                                           is_train=True)\n",
    "#     if df_val is not None:\n",
    "#         X_val,_,_ = preprocessing(X_val,\n",
    "#                                   numeric_preprocessor,categorical_preprocessor,\n",
    "#                                   is_train=False)\n",
    "\n",
    "#     #Build model & optimizer\n",
    "#     model = create_model(trial,X_train.shape[1])\n",
    "#     optimizer = create_optimizer(trial)\n",
    "    \n",
    "#     callbacks = []\n",
    "#     if use_pruner:\n",
    "#         callbacks.append(optuna.integration.TFKerasPruningCallback(trial,'val_f1_m'))\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy',optimizer=optimizer,\n",
    "#                   metrics=[f1_m],\n",
    "#                  )\n",
    "#     history = model.fit(X_train,y_train,\n",
    "#                         epochs=trial.suggest_int('epoch',15,50),\n",
    "#                         batch_size=64,\n",
    "#                         validation_data=(X_val,y_val) if df_val is not None else None,\n",
    "#                         callbacks=callbacks,\n",
    "#                         verbose=False\n",
    "#                        )\n",
    "#     if df_val is not None:\n",
    "#         return np.mean(history.history['val_f1_m'])\n",
    "#     else:\n",
    "#         return model\n",
    "\n",
    "# ---------------------------- TRAINING FUNCTION ----------------------------\n",
    "\n",
    "def train(trial, df_train, df_val=None, use_pruner=False):\n",
    "    X_train, y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "    X_val, y_val = None, None\n",
    "\n",
    "    if df_val is not None:\n",
    "        X_val, y_val = df_val.drop(columns=['y']), df_val['y']\n",
    "\n",
    "    # Preprocessing\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    X_train, numeric_preprocessor, categorical_preprocessor = preprocessing(X_train, numeric_preprocessor, categorical_preprocessor, is_train=True)\n",
    "    \n",
    "    if df_val is not None:\n",
    "        X_val, _, _ = preprocessing(X_val, numeric_preprocessor, categorical_preprocessor, is_train=False)\n",
    "\n",
    "    model = create_model(trial, X_train.shape[1])\n",
    "    optimizer = create_optimizer(trial)\n",
    "\n",
    "    callbacks = []\n",
    "    if use_pruner and df_val is not None:\n",
    "        callbacks.append(optuna.integration.TFKerasPruningCallback(trial, 'val_f1_m'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_m])\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=trial.suggest_int('epoch', 15, 50),\n",
    "        batch_size=64,\n",
    "        validation_data=(X_val, y_val) if df_val is not None else None,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    if df_val is not None:\n",
    "        return np.mean(history.history['val_f1_m'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c53415-d85e-44db-bb7e-e7e7dffe9fc7",
   "metadata": {},
   "source": [
    "#### The Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c0497e1-47e9-4e0c-b60e-a833c54bee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial: optuna.trial.Trial, df_train: pd.DataFrame, use_pruner: bool = False): \n",
    "#     #Split into Train and Validation data\n",
    "#     df_train_hp, df_val = train_test_split(df_train, test_size=0.1, random_state=0)\n",
    "    \n",
    "#     # Train and Validate Model\n",
    "#     val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
    "        \n",
    "#     return val_f1_score\n",
    "\n",
    "# ---------------------------- OBJECTIVE FUNCTION ----------------------------\n",
    "\n",
    "def objective(trial, df_train, use_pruner=False):\n",
    "    df_train_hp, df_val = train_test_split(df_train, test_size=0.1, random_state=0)\n",
    "    val_f1_score = train(trial, df_train_hp, df_val, use_pruner)\n",
    "    return val_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9812db-b4bc-4ff6-add6-f698b6068987",
   "metadata": {},
   "source": [
    "#### Final Training & Evaluation Function: `To Test The Best Set of Hyperparmeters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d662b5bb-b7bc-47b5-a112-1f1ac750b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_and_evaluate_final(df_train: pd.DataFrame, df_test: pd.DataFrame, **kwargs):\n",
    "#     X_train,y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "#     X_test,y_test = df_test.drop(columns=['y']), df_test['y'] \n",
    "    \n",
    "#     # Preprocessing\n",
    "#     numeric_preprocessor = StandardScaler()\n",
    "#     categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "#     X_train,numeric_preprocessor,categorical_preprocessor = preprocessing(X_train,\n",
    "#                                                                           numeric_preprocessor,\n",
    "#                                                                           categorical_preprocessor,\n",
    "#                                                                           is_train=True)\n",
    "#     X_test,_,_ = preprocessing(X_test,numeric_preprocessor,categorical_preprocessor,\n",
    "#                               is_train=False)\n",
    "\n",
    "#     #Build model\n",
    "#     input_size = X_train.shape[1]\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(input_size,input_shape=(input_size,),activation='relu')) \n",
    "\n",
    "#     num_layers = kwargs.get('num_layers',0)  \n",
    "#     for layer_i in range(num_layers):  \n",
    "#         n_units = kwargs.get(f'n_units_layer_{layer_i}',0)  \n",
    "#         dropout_rate = kwargs.get(f'dropout_rate_layer_{layer_i}',0)  \n",
    "#         actv_func = kwargs.get(f'actv_func_layer_{layer_i}','relu')  \n",
    "\n",
    "#         model.add(Dropout(dropout_rate))  \n",
    "#         model.add(Dense(n_units,activation=actv_func)) \n",
    "\n",
    "#     model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "#     #Build Optimizer\n",
    "#     opt_kwargs = {} \n",
    "#     opt_selected = kwargs.get('optimizer', 'Adam')\n",
    "#     if opt_selected == 'SGD': \n",
    "#         opt_kwargs['lr'] = kwargs.get('sgd_lr',1e-5) \n",
    "#         opt_kwargs['momentum'] = kwargs.get('sgd_momentum',1e-5) \n",
    "#     else: #’Adam’ \n",
    "#         opt_kwargs['lr'] = kwargs.get('adam_lr',1e-5) \n",
    "\n",
    "#     optimizer = getattr(tf.optimizers,opt_selected)(**opt_kwargs) \n",
    "    \n",
    "#     #Training process\n",
    "#     model.compile(loss='binary_crossentropy',optimizer=optimizer,\n",
    "#                   metrics=[f1_m],\n",
    "#                  )\n",
    "#     print(model.summary())\n",
    "#     history = model.fit(X_train,y_train,\n",
    "#                         epochs=kwargs.get('epoch',15),\n",
    "#                         batch_size=64,\n",
    "#                         validation_data=None,\n",
    "#                         verbose=True\n",
    "#                        )\n",
    "    \n",
    "#     # Evaluation Process\n",
    "#     y_test_pred_probas = model.predict(X_test)\n",
    "#     y_test_pred = [1 if x[0]>0.5 else 0 for x in y_test_pred_probas]\n",
    "    \n",
    "#     print(\"=\"*100)\n",
    "#     print(\"F1-Score on Test Data: \",f1_score(y_test, y_test_pred))\n",
    "\n",
    "# ---------------------------- FINAL TRAINING ----------------------------\n",
    "\n",
    "def train_and_evaluate_final(df_train, df_test, **kwargs):\n",
    "    X_train, y_train = df_train.drop(columns=['y']), df_train['y']\n",
    "    X_test, y_test = df_test.drop(columns=['y']), df_test['y']\n",
    "\n",
    "    numeric_preprocessor = StandardScaler()\n",
    "    categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "    X_train, numeric_preprocessor, categorical_preprocessor = preprocessing(X_train, numeric_preprocessor, categorical_preprocessor, is_train=True)\n",
    "    X_test, _, _ = preprocessing(X_test, numeric_preprocessor, categorical_preprocessor, is_train=False)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(X_train.shape[1], input_shape=(X_train.shape[1],), activation='relu'))\n",
    "\n",
    "    for i in range(kwargs.get('num_layers', 0)):\n",
    "        model.add(Dropout(kwargs.get(f'dropout_rate_layer_{i}', 0)))\n",
    "        model.add(Dense(kwargs.get(f'n_units_layer_{i}', 10), activation=kwargs.get(f'actv_func_layer_{i}', 'relu')))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt_name = kwargs.get('optimizer', 'Adam')\n",
    "    if opt_name == 'SGD':\n",
    "        optimizer = SGD(\n",
    "            learning_rate=kwargs.get('sgd_lr', 1e-5),\n",
    "            momentum=kwargs.get('sgd_momentum', 1e-5)\n",
    "        )\n",
    "    else:\n",
    "        optimizer = Adam(learning_rate=kwargs.get('adam_lr', 1e-5))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=[f1_m])\n",
    "    model.fit(X_train, y_train, epochs=kwargs.get('epoch', 15), batch_size=64, verbose=1)\n",
    "\n",
    "    y_test_pred_proba = model.predict(X_test)\n",
    "    y_test_pred = [1 if x > 0.5 else 0 for x in y_test_pred_proba]\n",
    "\n",
    "    print(\"=\" * 100)\n",
    "    print(\"F1-Score on Test Data:\", f1_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0fa91c-0669-4230-a514-8935149b3291",
   "metadata": {},
   "source": [
    "## TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ecf0b0a-c15c-4af2-bbb8-f1c79738341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/joaquinromero/Desktop/HPTP/data/train.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "730766fc-afef-42ba-b1c7-9a234b2be920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a25603-d184-4752-86c0-aaee0e7c9eb2",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38361f39-a089-4f7e-ac20-46747f27dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b7e7d-d2e9-4a07-8392-16c0342dc0a1",
   "metadata": {},
   "source": [
    "#### Placing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47de4461-763d-47fa-b311-9303a3f15f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats = list(df_train.drop(columns='y').select_dtypes(include=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325add34-5fa4-4ba5-ac3b-bf17152e6fd7",
   "metadata": {},
   "source": [
    "#### Placing Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f88371bc-bfa9-4e1a-95ab-513e1f804555",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = list(df_train.drop(columns='y').select_dtypes(exclude=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62541d3c-7dde-4358-aa27-591b02e07ab2",
   "metadata": {},
   "source": [
    "### Performing Hyperparameter Tuning with TPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "638e5652-01d1-4b66-9e8a-c98bea4fcf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction='maximize',\n",
    "#                             sampler=optuna.samplers.TPESampler(seed=0),\n",
    "#                            )\n",
    "# study.optimize(lambda trial: objective(trial, df_train),\n",
    "#                n_trials=50, n_jobs=-1,\n",
    "#               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d900ea82-5c74-483b-83cb-e88bb20f7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best Trial:\")\n",
    "# best_trial = study.best_trial\n",
    "\n",
    "# print(\"    Value: \", best_trial.value)\n",
    "\n",
    "# print(\"    Hyperparameters: \")\n",
    "# for key, value in best_trial.params.items():\n",
    "#     print(f\"        {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1cf37ffd-35c2-44a2-a912-4deb7554e61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fba37d34-61a9-4c65-96c1-821111523b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_evaluate_final(df_train, df_test, **best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a195777-944b-4d16-8daf-0947e68bd1da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad13cbad-14a3-4402-8955-ca81d7b65720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
