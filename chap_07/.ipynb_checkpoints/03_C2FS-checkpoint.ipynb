{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198b9848-cc68-41d3-8edd-719476652a80",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning via Scikit-Learn\n",
    "\n",
    "## Coarse-to-Fine Search\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "470832f8-3b76-48e3-b840-535361ddd96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# StatsModel\n",
    "import scipy\n",
    "from scipy.stats import randint,truncnorm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import ParameterSampler, cross_val_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeaf9cd-f70f-48b0-be76-164e07862e20",
   "metadata": {},
   "source": [
    "#### Technical Requirements: `CoarseToFineSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bee5784-b0ce-4925-994a-39b0e9f0ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoarseToFineSearchCV:\n",
    "    def __init__(self,\n",
    "                 estimator,\n",
    "                 param_distributions,\n",
    "                 random_iters,\n",
    "                 top_n_percentile,\n",
    "                 continuous_hyperparams=[],\n",
    "                 worse_score = 0,\n",
    "                 n_iter=10,\n",
    "                 scoring=None,\n",
    "                 n_jobs=None,\n",
    "                 refit=True,\n",
    "                 cv=None,\n",
    "                 random_state=0,\n",
    "                 verbose=0\n",
    "                ):\n",
    "\n",
    "        self.estimator = estimator\n",
    "        self.param_distributions = param_distributions\n",
    "        self.random_iters = random_iters\n",
    "        self.top_n_percentile = top_n_percentile\n",
    "        self.continuous_hyperparams = continuous_hyperparams\n",
    "        self.worse_score = worse_score\n",
    "        self.n_iter = n_iter\n",
    "        self.scoring = scoring\n",
    "        self.n_jobs = n_jobs\n",
    "        self.refit = refit\n",
    "        self.cv = cv\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.best_params_ = {}\n",
    "        self.best_score_ = None\n",
    "    \n",
    "\n",
    "    def fit(self,X,y):\n",
    "        new_param_distributions = self.param_distributions.copy()\n",
    "        best_params_dict = {'score':self.worse_score,'params':[]}\n",
    "\n",
    "        for epoch in range(self.n_iter):\n",
    "            if self.verbose >= 2:\n",
    "                print(\"Hyperparameter space\")\n",
    "                print(new_param_distributions)\n",
    "\n",
    "\n",
    "            # List of sampled hyperparameter combinations will be used for random search\n",
    "            param_list = list(ParameterSampler(new_param_distributions, \n",
    "                                               n_iter=self.random_iters,\n",
    "                                               random_state=self.random_state))\n",
    "\n",
    "            # Searching the Best Parameters with Random Search\n",
    "            rs_results_dict = {}\n",
    "            for random_iter in range(min(self.random_iters,len(param_list))):\n",
    "                # Get the set of parameter for this iteration\n",
    "                strategy_params = param_list[random_iter]\n",
    "                \n",
    "                estimator = clone(self.estimator).set_params(**strategy_params)\n",
    "\n",
    "                results = np.mean(cross_val_score(estimator,X, y, \n",
    "                                                  cv=self.cv, scoring=self.scoring,\n",
    "                                                  n_jobs=self.n_jobs\n",
    "                                                  )\n",
    "                                 )\n",
    "\n",
    "                rs_results_dict[tuple(strategy_params.values())] = {'score':results}\n",
    "\n",
    "                if results >= best_params_dict['score']:\n",
    "                    best_params_dict['score'] = results\n",
    "                    best_params_dict['params'] = list(strategy_params.values())\n",
    "\n",
    "            # Save the results in dataframe and sort it based on score\n",
    "            param_names = list(strategy_params.keys())\n",
    "            df_rs_results = pd.DataFrame(rs_results_dict).T.reset_index()\n",
    "            df_rs_results.columns = param_names + ['score']\n",
    "            df_rs_results = df_rs_results.sort_values(['score'],ascending=False).head(self.n_iter-epoch)\n",
    "\n",
    "            # If the best score from this epoch is worse than the best score, \n",
    "            # then append the best hyperaparameters combination to this epoch dataframe\n",
    "            if df_rs_results['score'].iloc[0] < best_params_dict['score'] and best_params_dict['params']:\n",
    "                new_row_dict = {}\n",
    "                new_row_dict['score'] = best_params_dict['score']\n",
    "                for idx, key in enumerate(param_names):\n",
    "                    new_row_dict[key] = best_params_dict['params'][idx]\n",
    "\n",
    "                df_rs_results = pd.concat([df_rs_results,pd.DataFrame({0:new_row_dict}).T]).reset_index(drop=True)\n",
    "                df_rs_results = df_rs_results.sort_values(['score'],ascending=False).head(self.n_iter-epoch)\n",
    "\n",
    "            if self.verbose >= 1:\n",
    "                display(df_rs_results)\n",
    "                print(df_rs_results.head(1).T.to_dict())\n",
    "\n",
    "            # Get the worse and best hyperparameter combinations\n",
    "            percentile_threshold = df_rs_results['score'].quantile(self.top_n_percentile/100)\n",
    "            promising_subspace = df_rs_results[df_rs_results['score']>=percentile_threshold]\n",
    "            df_rs_results_min = promising_subspace.min(axis=0)\n",
    "            df_rs_results_max = promising_subspace.max(axis=0)\n",
    "\n",
    "            # Generate new hyperparameter space based on current worse and best hyperparameter combinations\n",
    "            for key in new_param_distributions:\n",
    "                if isinstance(new_param_distributions[key],scipy.stats._distn_infrastructure.rv_frozen):\n",
    "                    # Currently only support truncnorm and randint distribution\n",
    "                    # You can add your own distribution here\n",
    "                    if key in self.continuous_hyperparams:\n",
    "                        new_param_distributions[key] = truncnorm(a=df_rs_results_min[key],b=df_rs_results_max[key]+1e-6,\n",
    "                                                                 loc=(0.8*df_rs_results_min[key]+0.2*df_rs_results_max[key]), \n",
    "                                                                 scale=(0.8*df_rs_results_min[key]+0.2*df_rs_results_max[key])*2)\n",
    "                    else:\n",
    "                        new_param_distributions[key] = randint(int(df_rs_results_min[key]), int(df_rs_results_max[key])+1)\n",
    "                elif isinstance(new_param_distributions[key][0],str) or isinstance(new_param_distributions[key][0],bool):\n",
    "                    new_param_distributions[key] = tuple(promising_subspace[key].unique())\n",
    "                elif isinstance(new_param_distributions[key][0],int):\n",
    "                    new_param_distributions[key] = [i for i in range(int(df_rs_results_min[key]), int(df_rs_results_max[key])+1)]\n",
    "                elif isinstance(new_param_distributions[key][0],float):\n",
    "                    new_param_distributions[key] = list(np.linspace(df_rs_results_min[key], df_rs_results_max[key], \n",
    "                                                                    len(param_distributions[key])))\n",
    "                else:\n",
    "                    new_param_distributions[key] = self.param_distributions[key]\n",
    "            \n",
    "            if self.verbose >= 1:\n",
    "                print(\"=\"*100)\n",
    "        \n",
    "        for i, key in enumerate(param_names):\n",
    "            self.best_params_[key] = best_params_dict['params'][i]\n",
    "        self.best_score_ = best_params_dict['score']\n",
    "        \n",
    "        if self.refit:\n",
    "            self.estimator = self.estimator.set_params(**self.best_params_)\n",
    "            self.estimator.fit(X,y)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        if self.refit:\n",
    "            return self.estimator.predict(X)\n",
    "        else:\n",
    "            print(\"Estimator is not refitted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb049cd-ee19-405d-868f-6ef71cefd188",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af28927d-107d-43b6-84ef-0ae372195017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/joaquinromero/Desktop/HPTP/data/train.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1951e9f-83c7-4ca4-9627-96398cf098a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = df['y'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bcc47d-2c01-42f0-b64e-d954308887b3",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b6722b-8a7c-4ea9-843a-a5aa80c3d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0da77a-8c99-4d0f-bf6a-faac2a16823c",
   "metadata": {},
   "source": [
    "#### Placing Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87bc1a68-8069-4db5-a0ae-391385738e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_feats = list(df_train.drop(columns='y').select_dtypes(include=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d176dc-76b2-462e-940e-43b09377d4ff",
   "metadata": {},
   "source": [
    "#### Placing Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81576cee-5987-4bb5-9e21-1f879a4944de",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_feats = list(df_train.drop(columns='y').select_dtypes(exclude=np.number).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32cb3cb-337f-4cd5-8427-187ca3ca859d",
   "metadata": {},
   "source": [
    "### Pre-Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1de5d38-3be9-4a51-a42f-82f4c213daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization Pre-processing for Numerical Features\n",
    "numeric_preprocessor = StandardScaler()\n",
    "\n",
    "# One-Hot-Encoding Pre-processing for Categorical Features\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d591303-3e39-4d9d-9fd4-4bf8be4e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_preprocessor, numerical_feats),\n",
    "        (\"cat\", categorical_preprocessor, categorical_feats),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcdb194-1965-4f64-a745-ad04c6f0fce6",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1bd036d-6659-4dda-bbb6-ff68d7a87e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), \n",
    "           (\"model\", RandomForestClassifier(random_state=0))]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b6907-46b1-473e-a523-c302cca00894",
   "metadata": {},
   "source": [
    "#### Placing All Features for Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fff8969-b037-4262-bf6d-4eae25b86766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40689 entries, 17974 to 2732\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        40689 non-null  int64 \n",
      " 1   job        40689 non-null  object\n",
      " 2   marital    40689 non-null  object\n",
      " 3   education  40689 non-null  object\n",
      " 4   default    40689 non-null  object\n",
      " 5   balance    40689 non-null  int64 \n",
      " 6   housing    40689 non-null  object\n",
      " 7   loan       40689 non-null  object\n",
      " 8   contact    40689 non-null  object\n",
      " 9   day        40689 non-null  int64 \n",
      " 10  month      40689 non-null  object\n",
      " 11  duration   40689 non-null  int64 \n",
      " 12  campaign   40689 non-null  int64 \n",
      " 13  pdays      40689 non-null  int64 \n",
      " 14  previous   40689 non-null  int64 \n",
      " 15  poutcome   40689 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 5.3+ MB\n"
     ]
    }
   ],
   "source": [
    "X_train_full = df_train.drop(columns=['y'])\n",
    "y_train = df_train['y']\n",
    "\n",
    "X_train_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec326569-d467-4c1a-ac6d-213d02806473",
   "metadata": {},
   "source": [
    "#### Placing All Features for Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "475231bc-887d-4c38-8a49-c513fc0a6b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4522 entries, 14001 to 25978\n",
      "Data columns (total 16 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4522 non-null   int64 \n",
      " 1   job        4522 non-null   object\n",
      " 2   marital    4522 non-null   object\n",
      " 3   education  4522 non-null   object\n",
      " 4   default    4522 non-null   object\n",
      " 5   balance    4522 non-null   int64 \n",
      " 6   housing    4522 non-null   object\n",
      " 7   loan       4522 non-null   object\n",
      " 8   contact    4522 non-null   object\n",
      " 9   day        4522 non-null   int64 \n",
      " 10  month      4522 non-null   object\n",
      " 11  duration   4522 non-null   int64 \n",
      " 12  campaign   4522 non-null   int64 \n",
      " 13  pdays      4522 non-null   int64 \n",
      " 14  previous   4522 non-null   int64 \n",
      " 15  poutcome   4522 non-null   object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 600.6+ KB\n"
     ]
    }
   ],
   "source": [
    "X_test_full = df_test.drop(columns=['y'])\n",
    "y_test = df_test['y']\n",
    "\n",
    "X_test_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6f461-77b3-4042-a2b0-c1f4b6bfdedf",
   "metadata": {},
   "source": [
    "#### Calculating F1-Score on Test Data without Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21ee9aa2-82b4-4767-8ca5-98d9b351b2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5035971223021583\n"
     ]
    }
   ],
   "source": [
    "# Fitting The Pipeline on Train Data \n",
    "pipe.fit(X_train_full,y_train)\n",
    "\n",
    "# Evaluating on the Test Data \n",
    "y_pred = pipe.predict(X_test_full)\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562d2eae-7f26-48a6-911f-21d07db4d16f",
   "metadata": {},
   "source": [
    "#### Defining The Hyperparameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80db64ab-2354-4095-9b57-c63eff97c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_space = { \n",
    "\"model__n_estimators\": randint(5, 200), \n",
    "\"model__criterion\": [\"gini\", \"entropy\"],\n",
    "\"model__class_weight\": [\"balanced\",\"balanced_subsample\"],\n",
    "\"model__min_samples_split\": truncnorm(a=0,b=0.5,loc=0.005, scale=0.01),\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6a33f-8e83-46e6-a104-5d33088cb57b",
   "metadata": {},
   "source": [
    "### Performing `The Coarse-to-Fine Search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bff0106-b31a-4b64-aca0-7b6d6cad369d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d21ed1-da86-416d-9ba1-9eb0da98ce8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc885e13-5932-492a-9eb7-b509a0833ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8953a6d5-4a26-4fe5-8007-a9f6cdf2deaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf8f5e-734e-4d55-9391-b280d3ea04aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075b7d6-366e-498b-b8af-7fc6bd8d7051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c6185e-752f-480e-8797-409662b82791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c5b2c-795c-45e1-9f1d-3140429ccd03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
